{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What does one mean by the term \"machine learning\"?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "machine learning (ML) is a type of artificial intelligence (AI) that allows software applications to become more accurate at\n",
    "predicting outcomes without being explicitly programmed to do so. Machine learning algorithms use historical data as \n",
    "input to predict new output values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Can you think of 4 distinct types of issues where it shines?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1- recommending products\n",
    "2- customer segmentation\n",
    "3- sentiment analysis\n",
    "4- demand forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.What is a labeled training set, and how does it work?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Labels are the values of the response variables (what’s being predicted) that are used by the algorithm along with \n",
    "the feature variables (predictors).\n",
    "machine learning success is derived from the availability of labeled data in the form of a training set and test set that are\n",
    "used by the learning algorithm. The separation of the data into a training portion and a test portion is the way the algorithm \n",
    "learns.\n",
    "Labelled data which is used for training part is known as labeled training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.What are the two most important tasks that are supervised?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The two most common supervised tasks are regression and classification. Common unsupervised tasks include clustering, \n",
    "visualization, dimensionality reduction, and association rule learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Can you think of four examples of unsupervised tasks?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K-means clustering.\n",
    "KNN (k-nearest neighbors)\n",
    "Hierarchal clustering.\n",
    "Anomaly detection.\n",
    "Neural Networks.\n",
    "Principle Component Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.State the machine learning model that would be best to make a robot walk through various unfamiliar terrains?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reinforced ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Which algorithm will you use to divide your customers into different groups?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clustering algorithms kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Will you consider the problem of spam detection to be a supervised or unsupervised learning problem?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.What is the concept of an online learning system?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Online learning is an approach used in Machine Learning that ingests sample of real-time data one observation at a time.\n",
    "Online learning models process one sample of data at a time – thus be significantly more efficient both in time and space with \n",
    "more practical batch algorithms.\n",
    "For example, having a personalised shopping experience where the model constantly learns the real-time user behaviour with an \n",
    "attempt to provide personalised shopping is crucial for every customer-centric business model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.What is out-of-core learning, and how does it differ from core learning?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The term out-of-core typically refers to processing data that is too large to fit into a computer’s main memory.\n",
    "In such a case, an out-of-core algorithm would try to access all relevant data in one sequence.\n",
    "Core ML is designed to seamlessly take advantage of powerful hardware technology including CPU, GPU, and Neural Engine, \n",
    "in the most efficient way in order to maximize performance while minimizing memory and power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.What kind of learning algorithm makes predictions using a similarity measure?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Instance based ml algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.What's the difference between a model parameter and a hyperparameter in a learning algorithm?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model parameters are estimated based on the data during model training and model hyperparameters are set manually and\n",
    "are used in processes to help estimate model parameters.\n",
    "Model hyperparameters are often referred to as parameters because they are the parts of the machine learning that \n",
    "must be set manually and tuned.\n",
    "Basically, parameters are the ones that the “model” uses to make predictions etc. For example, the weight coefficients in a linear regression model. Hyperparameters are the ones that help with the learning process. For example, number of clusters in K-Means, shrinkage factor in Ridge Regression. They won’t appear in the final prediction piece, but they have a large influence on how the parameters would look like after the learning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.What are the criteria that model-based learning algorithms look for? What is the most popular method they use to \n",
    "achieve success? What method do they use to make predictions?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The goal for a model-based algorithm is to be able to generalize to new examples. To do this, model based algorithms search \n",
    "for optimal values for the model's parameters, often called theta. This searching, or \"learning\", is what machine learning \n",
    "is all about. Model-based system learn by minimizing a cost function that measures how bad the system is at making predicitons \n",
    "on new data, plus a penalty for model complexity if the model is regularized. To make a prediction, a new instance's features \n",
    "are fed into a hypothesis function which uses the minimized theta found by repeatedly running the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.Can you name four of the most important Machine Learning challenges?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not gathering enough data, or sampling noise. Sampling noise means we'll have non-representative data as a result of chance.\n",
    "\n",
    "Using a dataset that is not representative of the cases you want to generalize to. This is called sampling bias. For example, if you want to train an algorithm with \"cat videos\", and all your videos are from YouTube, you're actually training an algorithm to learn about \"YouTube cat videos.\"\n",
    "\n",
    "Your dataset is full of missing values, outliers, and noise (poor measurments).\n",
    "\n",
    "The features in your dataset are irrelevant. Garbage in, garbage out.\n",
    "\n",
    "Feature selection - choose the most relevant features from your dataset\n",
    "Feature extraction - combine features in your dataset to generate a new, more useful feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.What happens if the model performs well on the training data but fails to generalize the results to new situations? \n",
    "Can you think of three different options?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is a case where the model is overfitting the training data. To couteract overfitting, we can reduce the complexity \n",
    "of the model by removing features or constraining the parameters. We could gather more data. Finally we can reduce noisiness \n",
    "in the data by fixing errors and removing outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.What exactly is a test set, and why would you need one?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When we want to know how well our model generalizes to new cases we prefer to use a test set instead of actually deploying \n",
    "the system. To build the test set we split the training data (50-50, 60-40, 80-20 are common splits) into a training set and \n",
    "test set. Our model is training with the training set. Then we use the model to run predictions on the test set. Our error rate \n",
    "on the test set is called the generalization error or out-of-sample error. This error tells us how well our model performs on \n",
    "examples it has never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.What is a validation set's purpose?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's say we have a linear model and we want to perform some hyperparameter tuning to reduce the generalization error. One way to do this 100 different models with 100 different hyperparameter values using the training set and finding the generalization error with the test set. You find the best hyperparameter value gives you 5% generalization error.\n",
    "\n",
    "So you launch the model into production and find you're seeing 15% generalization error. This isn't going as expected. What happened?\n",
    "\n",
    "The problem is that for each iteration of hyperparameter tuning, you measured the generalization error then updated the model using the same test set. In other words, your produced the best generalization error for the test set. The test set no longer represents cases the model hasn't seen before.\n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you are happy about your model you run a single final test against the test set to get an estimate of the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) What can go wrong if you tune hyperparameters using the test set?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your model will not be generalizable to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) What is cross-validation and why would you prefer it to a validation set?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cross-validation helps us compare models without wasting too much training data in the validation set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
